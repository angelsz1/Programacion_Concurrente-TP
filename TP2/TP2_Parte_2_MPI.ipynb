{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TP2 Parte 2 - MPI"
      ],
      "metadata": {
        "id": "UbF2cVssjsq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Ejercicio - Hola Mundo con MPI"
      ],
      "metadata": {
        "id": "d9JsV0Xlj4DB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Preguntas del ejercicio\n",
        "Ejecute este ejemplo para  4  o m치s instancias y responda:\n",
        "\n",
        "a) **쯈u칠 funci칩n realiza la instancia maestra? 쯈u칠 funci칩n realizan las instancias esclavas?**\n",
        "\n",
        "游댱La funci칩n que realiza la instancia maestra es initWork con los siguientes par치metros:\n",
        "* comm: instancia del comunicador MPI, en este caso MPI.COMM_WORLD, que incluye a todos los procesos involucrados en la ejecuci칩n paralela.\n",
        "* workTimes: array de enteros, que representarian los trabajos que se les va a asignar a los esclavos.\n",
        "* numProcesses: n칰mero de procesos totales ejecutados, contando igualmente al proceso maestro.\n",
        "\n",
        "La funci칩n se compone de 4 partes. Para explicarlo mejor, me baso en esta situaci칩n: tengo 4 esclavos y 12 trabajos. Los trabajos son t0, t1, ... t11. Los esclavos son p1, p2, p3, p4 (ya que p0 ser칤a el maestro).\n",
        "\n",
        "Primero, \"asigna\" a cada esclavo un trabajo (en este contexto, sus horas de descanso del empleado), es decir, env칤a una posici칩n del array a su respectivo proceso.\n",
        "p1 -> t0 (\"trabajar치 en\"),\n",
        "p2 -> t1,\n",
        "p3 -> t2,\n",
        "p4 -> t3\n",
        "\n",
        "Segundo, los trabajos restantes se van asignando a medida que terminan los esclavos sus trabajos previos. El maestro se queda esperando a recibir los resultado del trabajo terminado de los esclavos para asignarles el siguiente.\n",
        "Continuando con el ejemplo, t4 a t11 no hab칤an sigo asignados. Si p3 (no importa que esclavo, MPI.ANY_SOURCE) termina, se le asigna t4. As칤, hasta que todos los trabajos hayan sido asignados.\n",
        "\n",
        "Tercero, una vez que todos los trabajos fueron asignados, el maestro tambi칠n se encarga de recibir estos 칰ltimos trabajos a pesar de que ya no tiene que asignar m치s. En el ejemplo, se quedar칤a esperando los trabajos terminados t8, t9, t10 y t11.\n",
        "\n",
        "Cuarto y 칰ltimo, notifica a los esclavos que se completaron todos los trabajos por medio de send.\n",
        "\n",
        "游댱La funci칩n que realiza las instancias esclavas es doWork con el siguientes par치metro:\n",
        "* comm: instancia del comunicador MPI.\n",
        "El proceso esclavo se queda esperando lo que el proceso maestro le envi칩. Se mantiene descansando (sleep) seg칰n ese valor recibido y envia su resultado (el mismo valor). Si el tag corresponde al fin de trabajo, finaliza. Caso contrario, vuelve a quedar a la escucha.\n",
        "\n",
        "b) **쮺u치ntas de esas instancias ejecuta la funci칩n main(), initWork() y doWork()?**\n",
        "\n",
        "Siendo N el n칰mero total de procesos que participan.\n",
        "La funci칩n main() es ejecutado N veces, osea por todos los procesos.\n",
        "La funci칩n initWork() una vez, solamente por el proceso maestro, cuyo id = 0.\n",
        "La funci칩n doWork() es ejecutado por todos los procesos esclavos. Es decir ser치 ejecutada N-1 veces.\n",
        "\n",
        "c) **쮺칩mo se diferencian los mensajes de trabajo o de finalizaci칩n?**\n",
        "\n",
        "Se diferencia por medio del tag.\n",
        "\n",
        "Los esclavos envian su resultado al maestro sin indicar un tag particular, por lo que se manda un default, el cual el maestro recibe.\n",
        "workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat)\n",
        "        recvcount += 1\n",
        "\n",
        "WORK_FLAG = 1. El maestro envia el trabajo con tag WORK_FLAG.\n",
        "\n",
        "END_WORK_FLAG = 2. El maestro envia el trabajo \"0\" con tag END_WORK a todos los procesos esclavos para avisarles que ya no quedan trabajos que atender.\n",
        "\n",
        "Los esclavos lo reciben cualquiera sea el tag (MPI.ANY_TAG) y trabajan (bajo este contexto, descansan seg칰n ese valor, pudiendo ser 0, min_tiempo_sleep a max_tiempo_sleep). A continuaci칩n, si el tag resultaba ser END_WORK, finalizan.\n",
        "\n",
        "d) **쮺칩mo implementar칤a la funci칩n BLAS axpy() con este patr칩n?쯉er칤a eficiente? Tips: Pide solo el planteo, no la implementaci칩n.**\n",
        "\n",
        "La operaci칩n axpy() es una operaci칩n lineal a partir de un escalar y 2 vectores.\n",
        "\n",
        "*Y <- aX + Y*\n",
        "\n",
        "MPI_Scatter(&sendbuf, sendcnt, sendtype, &recvbuf, ...)\n",
        "\n",
        "MPI_Gather(&sendbuf, sendcnt, sendtype, &recvbuf, ...)\n",
        "\n",
        "Podemos tener 2 arrays que representarian X e Y. Com MPI, a partir de MPI_Scatter distribuimos posiciones segmentadas de cada array. Donde cada proceso operar치 localmente con los datos asignados.\n",
        "\n",
        "A trav칠s de MPI_Gather, el proceso principal recibe los resultados de cada uno de estos y los vuelca en la direcci칩n del array Y.\n",
        "\n",
        "e) **쯈u칠 sucede cuando solo ejecuta con una sola instancia?**\n",
        "\n",
        "Al definir NRO = 1, indicamos que la cantidad de procesos que se ejecutar치n en paralelo sea uno. De esta forma, comm.Get_size() devuelve 1 efectivamente. El proceso maestro es parte, por lo que no hay \"empleados disponibles\". En el c칩digo, tras querer repartir el trabajo a 0 empleados, el numero de tareas es 0.\n",
        "\n",
        "numTasks = (numProcesses-1)*4\n",
        "\n",
        "numTasks = (1-1)*4 = 0\n",
        "\n",
        "f) Punto opcional: El c칩digo que ejecutan las instancias esclavas, tienen un error en su l칩gica. 쮺칩mo se podr칤a solucionar?"
      ],
      "metadata": {
        "id": "dUT7agILkKrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Armado del ambiente"
      ],
      "metadata": {
        "id": "yNdfhvbakUDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz9tN-lljqoj",
        "outputId": "1279c66a-310b-44a1-a593-8f46098e9e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (3.1.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install mpi4py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. C칩digo del programa en Lenguaje Python"
      ],
      "metadata": {
        "id": "c_l-CpO7jrxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Ejercicio2.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# --------------------------------------------\n",
        "# Formulario\n",
        "Max_tiempo_sleep =   1#@param {type: \"slider\", min: 1, max: 10}\n",
        "Min_tiempo_sleep =   0#@param {type: \"slider\", min: 0, max: 10}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Constantes de comunicacion\n",
        "WORK_FLAG = 1\n",
        "END_WORK_FLAG = 2\n",
        "# --------------------------------------------\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD # Instanciamos el tipo de comunicador a utilizar.\n",
        "    id = comm.Get_rank()  # Obtenemos el id como atributo del proceso que se ejecuta.\n",
        "\n",
        "    # Utilizamos el 0 para definir al procesos Maestro, cualquier otro id sera un esclavo.\n",
        "    if (id == 0) :\n",
        "        init() # Llamamos funcion init para eventos que requeriremos inicialmente solo 1 vez.\n",
        "        numProcesses = comm.Get_size()  # Obtenemos el numero de procesos totales ejecutados.\n",
        "        numTasks = (numProcesses-1)*4 # Se setea el numero de tareas.\n",
        "        workTimes = generateTasks(numTasks) # Se generan las tareas, en este caso seran\n",
        "        print(\"El jefe crea {} horas de descanso de sus empleados:\".format(workTimes.size), flush=True)\n",
        "        print(workTimes, flush=True)\n",
        "        initWork(comm, workTimes, numProcesses)\n",
        "    else:\n",
        "        doWork(comm)\n",
        "\n",
        "def generateTasks(numTasks):\n",
        "    #TODO: Cambiar la semilla del random para que se generen efectivamente diferentes numeros.\n",
        "    np.random.seed(1000)\n",
        "    return np.random.randint(low=Min_tiempo_sleep, high=Max_tiempo_sleep, size=numTasks)\n",
        "\n",
        "def init():\n",
        "  print()\n",
        "  print(\"Version MPI4py utilizada: {}\".format(MPI.Get_version()), flush=True)\n",
        "  print()\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print( \"Sistema de trabajo Suizo:\", flush=True)\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print()\n",
        "\n",
        "def initWork(comm, workTimes, numProcesses):\n",
        "    totalWork = workTimes.size\n",
        "    workcount = 0\n",
        "    recvcount = 0\n",
        "\n",
        "    print(\"Jefe enviando las tareas iniciales:\", flush=True)\n",
        "    for id in range(1, numProcesses):\n",
        "        if workcount < totalWork:\n",
        "            work=workTimes[workcount]\n",
        "            comm.send(work, dest=id, tag=WORK_FLAG) # Envia mensaje de iniciar trabajo con el dato correspondiente del array.\n",
        "            workcount += 1\n",
        "            print(\"Jefe envia trabajo y {} hs de descanso al empleado {}.\".format(work, id), flush=True)\n",
        "    print( \"------------------------------------\", flush=True)\n",
        "\n",
        "    # Mientras haya trabajo, se recibe el resultado de los empleados y se sigue enviando MAS trabajo.\n",
        "    while (workcount < totalWork) :\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat) # Recivimos resultados de los empleados.\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source() # Obtenemos el identificador del empleado.\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "        #send next work\n",
        "        work=workTimes[workcount]\n",
        "        comm.send(work, dest=workerId, tag=WORK_FLAG)\n",
        "        workcount += 1\n",
        "        print(\"Jefe envia nuevo trabajo y {} hs de descanso al empleado {}.\".format(work, workerId), flush=True)\n",
        "\n",
        "    while (recvcount < totalWork):\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat)\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source()\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "\n",
        "    for id in range(1, numProcesses):\n",
        "        comm.send(0, dest=id, tag=END_WORK_FLAG)\n",
        "\n",
        "\n",
        "def doWork(comm):\n",
        "    while(True):\n",
        "        stat = MPI.Status() # Obtiene el estado actual del empleado.\n",
        "        waitTime = comm.recv(source=0, tag=MPI.ANY_TAG, status=stat) # Obtiene lo enviado por el Jefe.\n",
        "        print(\"Soy el empleado con id {}, toca descanzo por {} hs.\".format(comm.Get_rank(), waitTime), flush=True)\n",
        "\n",
        "        if (stat.Get_tag() == END_WORK_FLAG):\n",
        "            print(\"Marca tarjeta el empleado {}.\".format(comm.Get_rank()), flush=True)\n",
        "            return\n",
        "        time.sleep(waitTime)\n",
        "        comm.send(waitTime, dest=0)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG-rAG5_kiA_",
        "outputId": "47df3b01-d38e-4607-94fc-4cfab9e7b810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Ejercicio2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 Ejecuci칩n del programa"
      ],
      "metadata": {
        "id": "oumTsozbkqdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par치metros de ejecuci칩n"
      ],
      "metadata": {
        "id": "ydfua9dxkvkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------\n",
        "#@title Par치metros de ejecuci칩n { vertical-output: true }\n",
        "NRO =   6#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "! mpirun --oversubscribe --allow-run-as-root -np $NRO python Ejercicio2.py"
      ],
      "metadata": {
        "id": "K17N9DXPkxMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Ejercicio Contar palabras"
      ],
      "metadata": {
        "id": "7H5zkFo7vPDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desarrollar un programa que permita obtener el valor m치ximo de un conjunto dado de forma distribuida.\n",
        "\n",
        "Las condiciones a tener en cuenta son:\n",
        "\n",
        "Debe trabajar con al menos, 4 procesos.\n",
        "El resultado final debe ser informado en cada proceso.\n",
        "Implementar comunicaci칩n por Buffer"
      ],
      "metadata": {
        "id": "-FkLl9zxvRsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_tp4.py\n",
        "\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "comm = MPI.COMM_WORLD\n",
        "size = comm.Get_size()\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "count = 12\n",
        "sendbuf = None\n",
        "recvbuf_ = None # resultado reduce\n",
        "\n",
        "if rank == 0:\n",
        "  sendbuf = np.empty([size, count], dtype='i') # creo matriz\n",
        "  sendbuf.T[:,:] = range(size) # asigno valores\n",
        "\n",
        "  print(\"Matriz generada\\n\", sendbuf)\n",
        "  print(\"Maximo check = \", sendbuf.max()) # este deber칤a ser el resultado final.\n",
        "\n",
        "## ---------------------- SCATTER ----------------------------------------------\n",
        "\n",
        "recvbuf = np.empty(count, dtype='i') # array vacio, fila\n",
        "\n",
        "comm.Scatter(sendbuf, recvbuf, root=0) # scatter(matriz, vector, root)\n",
        "print(f\"Scatter | Proceso: {rank} - Data: {recvbuf}\")\n",
        "\n",
        "# todos los procesos recibieron una parte de la matriz \"sendbuf\",\n",
        "# y lo alojan en un array previamente vacio y secuencial \"recvbuf\"\n",
        "\n",
        "## ------------------------ REDUCE ---------------------------------------------\n",
        "\n",
        "if rank == 0:\n",
        "  recvbuf_ = np.empty([1, count], dtype='i') #matriz de fila 1\n",
        "\n",
        "comm.Reduce(recvbuf, recvbuf_, op=MPI.MAX, root=0) # reduce(vector, matriz, op, root)\n",
        "\n",
        "if rank == 0:\n",
        "  print(\"Reduce | Soy proceso root. Maximos de cada columna: \", recvbuf_) #resultado matriz\n",
        "\n",
        "# el proceso root recibe el array \"recvbuf\" de cada proceso y\n",
        "# junto con la operaci칩n para obtener los m치ximos de cada COLUMNA de la matriz\n",
        "# se aloja el resultado en la matriz de una fila \"recvbuf_\".\n",
        "\n",
        "## ----------------------- BROADCAST -------------------------------------------\n",
        "\n",
        "if rank == 0:\n",
        "  max_final = recvbuf_.max() # variable con el maximo de maximos\n",
        "  data = np.array([max_final], dtype='i')\n",
        "else:\n",
        "  data = np.empty(1, dtype='i') # array de una sola posici칩n\n",
        "\n",
        "comm.Bcast(data, root=0)\n",
        "\n",
        "print(f\"Broadcast | Proceso: {rank} - Resultado final: {data[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaB1xiB6vg0i",
        "outputId": "dbe4af5d-df14-4a75-8d90-31656544fe52"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mpi_tp4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NRO = 4\n",
        "! mpirun --oversubscribe --allow-run-as-root -np $NRO python mpi_tp4.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aJNP5Bfvdz6",
        "outputId": "6c3b843d-7fe6-4c06-d176-4e116b53953f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz generada\n",
            " [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [2 2 2 2 2 2 2 2 2 2 2 2]\n",
            " [3 3 3 3 3 3 3 3 3 3 3 3]]\n",
            "Maximo check =  3\n",
            "Scatter | Proceso: 0 - Data: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Scatter | Proceso: 2 - Data: [2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Scatter | Proceso: 3 - Data: [3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "Scatter | Proceso: 1 - Data: [1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Reduce | Soy proceso root. Maximos de cada columna:  [[3 3 3 3 3 3 3 3 3 3 3 3]]\n",
            "Broadcast | Proceso: 0 - Resultado final: 3\n",
            "Broadcast | Proceso: 2 - Resultado final: 3\n",
            "Broadcast | Proceso: 1 - Resultado final: 3\n",
            "Broadcast | Proceso: 3 - Resultado final: 3\n"
          ]
        }
      ]
    }
  ]
}